import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots

# æœºå™¨å­¦ä¹ åº“
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import (
  accuracy_score, precision_score, recall_score, f1_score, roc_auc_score,
  confusion_matrix, classification_report, mean_squared_error, r2_score,
  roc_curve, precision_recall_curve
)

# åˆ†ç±»ç®—æ³•
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
from sklearn.neighbors import KNeighborsClassifier

# å›å½’ç®—æ³•
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.ensemble import RandomForestRegressor
from sklearn.svm import SVR

# èšç±»ç®—æ³•
from sklearn.cluster import KMeans, DBSCAN, AgglomerativeClustering
from sklearn.metrics import silhouette_score

def show():
  """æ˜¾ç¤ºæœºå™¨å­¦ä¹ é¡µé¢"""
  st.markdown('<h1 class="main-header">ğŸ¤– æœºå™¨å­¦ä¹ åˆ†æ</h1>', unsafe_allow_html=True)
  
  if st.session_state.data is None:
      st.warning("âš ï¸ è¯·å…ˆåœ¨æ•°æ®å¯¼å…¥é¡µé¢åŠ è½½æ•°æ®")
      return
  
  data = st.session_state.data
  
  # åˆ›å»ºæ ‡ç­¾é¡µ
  tab1, tab2, tab3, tab4 = st.tabs([
      "åˆ†ç±»ç®—æ³•", "å›å½’ç®—æ³•", "èšç±»åˆ†æ", "æ¨¡å‹è¯„ä¼°"
  ])
  
  with tab1:
      show_classification_analysis(data)
  
  with tab2:
      show_regression_analysis(data)
  
  with tab3:
      show_clustering_analysis(data)
  
  with tab4:
      show_model_evaluation(data)

def show_classification_analysis(data: pd.DataFrame):
  """æ˜¾ç¤ºåˆ†ç±»åˆ†æ"""
  st.markdown('<h2 class="sub-header">åˆ†ç±»ç®—æ³•</h2>', unsafe_allow_html=True)
  
  # é€‰æ‹©ç›®æ ‡å˜é‡å’Œç‰¹å¾å˜é‡
  all_cols = data.columns.tolist()
  
  target_var = st.selectbox("é€‰æ‹©ç›®æ ‡å˜é‡ï¼ˆåˆ†ç±»æ ‡ç­¾ï¼‰", all_cols)
  
  if target_var:
      feature_vars = st.multiselect(
          "é€‰æ‹©ç‰¹å¾å˜é‡",
          [col for col in all_cols if col != target_var],
          default=[col for col in all_cols if col != target_var][:5]
      )
      
      if not feature_vars:
          st.warning("è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªç‰¹å¾å˜é‡")
          return
      
      # æ£€æŸ¥ç›®æ ‡å˜é‡çš„ç±»å‹
      target_unique = data[target_var].nunique()
      
      if target_unique > 10:
          st.warning("ç›®æ ‡å˜é‡çš„å”¯ä¸€å€¼è¿‡å¤šï¼Œå¯èƒ½ä¸é€‚åˆåˆ†ç±»ä»»åŠ¡")
          return
      
      # é€‰æ‹©ç®—æ³•
      algorithm = st.selectbox(
          "é€‰æ‹©åˆ†ç±»ç®—æ³•",
          ["é€»è¾‘å›å½’", "éšæœºæ£®æ—", "æ”¯æŒå‘é‡æœº", "æœ´ç´ è´å¶æ–¯", "Kè¿‘é‚»"]
      )
      
      # æ•°æ®é¢„å¤„ç†é€‰é¡¹
      st.markdown("### æ•°æ®é¢„å¤„ç†")
      
      col1, col2 = st.columns(2)
      
      with col1:
          handle_missing = st.selectbox(
              "ç¼ºå¤±å€¼å¤„ç†",
              ["åˆ é™¤ç¼ºå¤±å€¼", "å‡å€¼å¡«å……", "ä¸­ä½æ•°å¡«å……"]
          )
      
      with col2:
          scale_features = st.checkbox("ç‰¹å¾æ ‡å‡†åŒ–", value=True)
      
      test_size = st.slider("æµ‹è¯•é›†æ¯”ä¾‹", 0.1, 0.5, 0.2, 0.05)
      
      if st.button("è®­ç»ƒæ¨¡å‹"):
          try:
              # æ•°æ®å‡†å¤‡
              model_data = data[[target_var] + feature_vars].copy()
              
              # å¤„ç†ç¼ºå¤±å€¼
              if handle_missing == "åˆ é™¤ç¼ºå¤±å€¼":
                  model_data = model_data.dropna()
              elif handle_missing == "å‡å€¼å¡«å……":
                  numeric_cols = model_data.select_dtypes(include=[np.number]).columns
                  model_data[numeric_cols] = model_data[numeric_cols].fillna(model_data[numeric_cols].mean())
              elif handle_missing == "ä¸­ä½æ•°å¡«å……":
                  numeric_cols = model_data.select_dtypes(include=[np.number]).columns
                  model_data[numeric_cols] = model_data[numeric_cols].fillna(model_data[numeric_cols].median())
              
              # ç¼–ç åˆ†ç±»å˜é‡
              le_dict = {}
              for col in model_data.columns:
                  if model_data[col].dtype == 'object':
                      le = LabelEncoder()
                      model_data[col] = le.fit_transform(model_data[col].astype(str))
                      le_dict[col] = le
              
              # åˆ†ç¦»ç‰¹å¾å’Œç›®æ ‡
              X = model_data[feature_vars]
              y = model_data[target_var]
              
              # åˆ’åˆ†è®­ç»ƒæµ‹è¯•é›†
              X_train, X_test, y_train, y_test = train_test_split(
                  X, y, test_size=test_size, random_state=42, stratify=y
              )
              
              # ç‰¹å¾æ ‡å‡†åŒ–
              if scale_features:
                  scaler = StandardScaler()
                  X_train_scaled = scaler.fit_transform(X_train)
                  X_test_scaled = scaler.transform(X_test)
              else:
                  X_train_scaled = X_train.values
                  X_test_scaled = X_test.values
              
              # é€‰æ‹©å’Œè®­ç»ƒæ¨¡å‹
              if algorithm == "é€»è¾‘å›å½’":
                  model = LogisticRegression(random_state=42, max_iter=1000)
              elif algorithm == "éšæœºæ£®æ—":
                  model = RandomForestClassifier(random_state=42, n_estimators=100)
              elif algorithm == "æ”¯æŒå‘é‡æœº":
                  model = SVC(random_state=42, probability=True)
              elif algorithm == "æœ´ç´ è´å¶æ–¯":
                  model = GaussianNB()
              elif algorithm == "Kè¿‘é‚»":
                  model = KNeighborsClassifier(n_neighbors=5)
              
              # è®­ç»ƒæ¨¡å‹
              model.fit(X_train_scaled, y_train)
              
              # é¢„æµ‹
              y_pred = model.predict(X_test_scaled)
              y_pred_proba = model.predict_proba(X_test_scaled) if hasattr(model, 'predict_proba') else None
              
              # æ˜¾ç¤ºç»“æœ
              show_classification_results(y_test, y_pred, y_pred_proba, model, feature_vars, algorithm)
              
              # ä¿å­˜æ¨¡å‹åˆ°session state
              st.session_state.trained_model = {
                  'model': model,
                  'scaler': scaler if scale_features else None,
                  'feature_vars': feature_vars,
                  'target_var': target_var,
                  'le_dict': le_dict,
                  'algorithm': algorithm
              }
              
          except Exception as e:
              st.error(f"æ¨¡å‹è®­ç»ƒå¤±è´¥: {str(e)}")

def show_classification_results(y_test, y_pred, y_pred_proba, model, feature_vars, algorithm):
  """æ˜¾ç¤ºåˆ†ç±»ç»“æœ"""
  st.markdown("### ğŸ¯ æ¨¡å‹æ€§èƒ½è¯„ä¼°")
  
  # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
  accuracy = accuracy_score(y_test, y_pred)
  precision = precision_score(y_test, y_pred, average='weighted')
  recall = recall_score(y_test, y_pred, average='weighted')
  f1 = f1_score(y_test, y_pred, average='weighted')
  
  # æ˜¾ç¤ºæŒ‡æ ‡
  col1, col2, col3, col4 = st.columns(4)
  
  with col1:
      st.metric("å‡†ç¡®ç‡", f"{accuracy:.3f}")
  with col2:
      st.metric("ç²¾ç¡®ç‡", f"{precision:.3f}")
  with col3:
      st.metric("å¬å›ç‡", f"{recall:.3f}")
  with col4:
      st.metric("F1åˆ†æ•°", f"{f1:.3f}")
  
  # æ··æ·†çŸ©é˜µ
  cm = confusion_matrix(y_test, y_pred)
  
  col1, col2 = st.columns(2)
  
  with col1:
      st.markdown("#### æ··æ·†çŸ©é˜µ")
      fig_cm = px.imshow(
          cm,
          text_auto=True,
          aspect="auto",
          title="æ··æ·†çŸ©é˜µ",
          labels=dict(x="é¢„æµ‹æ ‡ç­¾", y="çœŸå®æ ‡ç­¾")
      )
      st.plotly_chart(fig_cm, use_container_width=True)
  
  with col2:
      # åˆ†ç±»æŠ¥å‘Š
      st.markdown("#### åˆ†ç±»æŠ¥å‘Š")
      report = classification_report(y_test, y_pred, output_dict=True)
      report_df = pd.DataFrame(report).transpose()
      st.dataframe(report_df.round(3), use_container_width=True)
  
  # ROCæ›²çº¿ï¼ˆäºŒåˆ†ç±»ï¼‰
  if len(np.unique(y_test)) == 2 and y_pred_proba is not None:
      st.markdown("#### ROCæ›²çº¿")
      
      fpr, tpr, _ = roc_curve(y_test, y_pred_proba[:, 1])
      auc_score = roc_auc_score(y_test, y_pred_proba[:, 1])
      
      fig_roc = px.line(
          x=fpr, y=tpr,
          title=f"ROCæ›²çº¿ (AUC = {auc_score:.3f})",
          labels={'x': 'å‡æ­£ç‡', 'y': 'çœŸæ­£ç‡'}
      )
      fig_roc.add_shape(
          type="line", line=dict(dash="dash"),
          x0=0, x1=1, y0=0, y1=1
      )
      st.plotly_chart(fig_roc, use_container_width=True)
  
  # ç‰¹å¾é‡è¦æ€§ï¼ˆå¦‚æœæ¨¡å‹æ”¯æŒï¼‰
  if hasattr(model, 'feature_importances_'):
      st.markdown("#### ç‰¹å¾é‡è¦æ€§")
      
      importance_df = pd.DataFrame({
          'ç‰¹å¾': feature_vars,
          'é‡è¦æ€§': model.feature_importances_
      }).sort_values('é‡è¦æ€§', ascending=False)
      
      fig_importance = px.bar(
          importance_df,
          x='é‡è¦æ€§',
          y='ç‰¹å¾',
          orientation='h',
          title="ç‰¹å¾é‡è¦æ€§æ’åº"
      )
      st.plotly_chart(fig_importance, use_container_width=True)

def show_regression_analysis(data: pd.DataFrame):
  """æ˜¾ç¤ºå›å½’åˆ†æ"""
  st.markdown('<h2 class="sub-header">å›å½’ç®—æ³•</h2>', unsafe_allow_html=True)
  
  # é€‰æ‹©ç›®æ ‡å˜é‡å’Œç‰¹å¾å˜é‡
  numeric_cols = data.select_dtypes(include=[np.number]).columns.tolist()
  
  if len(numeric_cols) < 2:
      st.warning("éœ€è¦è‡³å°‘2ä¸ªæ•°å€¼å˜é‡è¿›è¡Œå›å½’åˆ†æ")
      return
  
  target_var = st.selectbox("é€‰æ‹©ç›®æ ‡å˜é‡ï¼ˆè¿ç»­å€¼ï¼‰", numeric_cols)
  
  if target_var:
      feature_vars = st.multiselect(
          "é€‰æ‹©ç‰¹å¾å˜é‡",
          [col for col in numeric_cols if col != target_var],
          default=[col for col in numeric_cols if col != target_var][:3]
      )
      
      if not feature_vars:
          st.warning("è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªç‰¹å¾å˜é‡")
          return
      
      # é€‰æ‹©ç®—æ³•
      algorithm = st.selectbox(
          "é€‰æ‹©å›å½’ç®—æ³•",
          ["çº¿æ€§å›å½’", "å²­å›å½’", "Lassoå›å½’", "éšæœºæ£®æ—å›å½’", "æ”¯æŒå‘é‡å›å½’"]
      )
      
      # æ•°æ®é¢„å¤„ç†é€‰é¡¹
      st.markdown("### æ•°æ®é¢„å¤„ç†")
      
      col1, col2 = st.columns(2)
      
      with col1:
          handle_missing = st.selectbox(
              "ç¼ºå¤±å€¼å¤„ç†",
              ["åˆ é™¤ç¼ºå¤±å€¼", "å‡å€¼å¡«å……", "ä¸­ä½æ•°å¡«å……"],
              key="reg_missing"
          )
      
      with col2:
          scale_features = st.checkbox("ç‰¹å¾æ ‡å‡†åŒ–", value=True, key="reg_scale")
      
      test_size = st.slider("æµ‹è¯•é›†æ¯”ä¾‹", 0.1, 0.5, 0.2, 0.05, key="reg_test_size")
      
      if st.button("è®­ç»ƒå›å½’æ¨¡å‹"):
          try:
              # æ•°æ®å‡†å¤‡
              model_data = data[[target_var] + feature_vars].copy()
              
              # å¤„ç†ç¼ºå¤±å€¼
              if handle_missing == "åˆ é™¤ç¼ºå¤±å€¼":
                  model_data = model_data.dropna()
              elif handle_missing == "å‡å€¼å¡«å……":
                  model_data = model_data.fillna(model_data.mean())
              elif handle_missing == "ä¸­ä½æ•°å¡«å……":
                  model_data = model_data.fillna(model_data.median())
              
              # åˆ†ç¦»ç‰¹å¾å’Œç›®æ ‡
              X = model_data[feature_vars]
              y = model_data[target_var]
              
              # åˆ’åˆ†è®­ç»ƒæµ‹è¯•é›†
              X_train, X_test, y_train, y_test = train_test_split(
                  X, y, test_size=test_size, random_state=42
              )
              
              # ç‰¹å¾æ ‡å‡†åŒ–
              if scale_features:
                  scaler = StandardScaler()
                  X_train_scaled = scaler.fit_transform(X_train)
                  X_test_scaled = scaler.transform(X_test)
              else:
                  X_train_scaled = X_train.values
                  X_test_scaled = X_test.values
              
              # é€‰æ‹©å’Œè®­ç»ƒæ¨¡å‹
              if algorithm == "çº¿æ€§å›å½’":
                  model = LinearRegression()
              elif algorithm == "å²­å›å½’":
                  model = Ridge(alpha=1.0, random_state=42)
              elif algorithm == "Lassoå›å½’":
                  model = Lasso(alpha=1.0, random_state=42)
              elif algorithm == "éšæœºæ£®æ—å›å½’":
                  model = RandomForestRegressor(random_state=42, n_estimators=100)
              elif algorithm == "æ”¯æŒå‘é‡å›å½’":
                  model = SVR(kernel='rbf')
              
              # è®­ç»ƒæ¨¡å‹
              model.fit(X_train_scaled, y_train)
              
              # é¢„æµ‹
              y_pred_train = model.predict(X_train_scaled)
              y_pred_test = model.predict(X_test_scaled)
              
              # æ˜¾ç¤ºç»“æœ
              show_regression_results(
                  y_train, y_pred_train, y_test, y_pred_test, 
                  model, feature_vars, algorithm
              )
              
          except Exception as e:
              st.error(f"å›å½’æ¨¡å‹è®­ç»ƒå¤±è´¥: {str(e)}")

def show_regression_results(y_train, y_pred_train, y_test, y_pred_test, model, feature_vars, algorithm):
  """æ˜¾ç¤ºå›å½’ç»“æœ"""
  st.markdown("### ğŸ“Š å›å½’æ¨¡å‹æ€§èƒ½è¯„ä¼°")
  
  # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
  train_r2 = r2_score(y_train, y_pred_train)
  test_r2 = r2_score(y_test, y_pred_test)
  train_rmse = np.sqrt(mean_squared_error(y_train, y_pred_train))
  test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))
  train_mae = np.mean(np.abs(y_train - y_pred_train))
  test_mae = np.mean(np.abs(y_test - y_pred_test))
  
  # æ˜¾ç¤ºæŒ‡æ ‡
  col1, col2 = st.columns(2)
  
  with col1:
      st.markdown("#### è®­ç»ƒé›†æ€§èƒ½")
      st.metric("RÂ²", f"{train_r2:.4f}")
      st.metric("RMSE", f"{train_rmse:.4f}")
      st.metric("MAE", f"{train_mae:.4f}")
  
  with col2:
      st.markdown("#### æµ‹è¯•é›†æ€§èƒ½")
      st.metric("RÂ²", f"{test_r2:.4f}")
      st.metric("RMSE", f"{test_rmse:.4f}")
      st.metric("MAE", f"{test_mae:.4f}")
  
  # é¢„æµ‹vså®é™…å€¼å›¾
  col1, col2 = st.columns(2)
  
  with col1:
      # è®­ç»ƒé›†
      fig_train = px.scatter(
          x=y_train, y=y_pred_train,
          title="è®­ç»ƒé›†ï¼šé¢„æµ‹å€¼ vs å®é™…å€¼",
          labels={'x': 'å®é™…å€¼', 'y': 'é¢„æµ‹å€¼'}
      )
      # æ·»åŠ ç†æƒ³çº¿
      min_val, max_val = min(y_train.min(), y_pred_train.min()), max(y_train.max(), y_pred_train.max())
      fig_train.add_shape(
          type="line", line=dict(dash="dash", color="red"),
          x0=min_val, x1=max_val, y0=min_val, y1=max_val
      )
      st.plotly_chart(fig_train, use_container_width=True)
  
  with col2:
      # æµ‹è¯•é›†
      fig_test = px.scatter(
          x=y_test, y=y_pred_test,
          title="æµ‹è¯•é›†ï¼šé¢„æµ‹å€¼ vs å®é™…å€¼",
          labels={'x': 'å®é™…å€¼', 'y': 'é¢„æµ‹å€¼'}
      )
      # æ·»åŠ ç†æƒ³çº¿
      min_val, max_val = min(y_test.min(), y_pred_test.min()), max(y_test.max(), y_pred_test.max())
      fig_test.add_shape(
          type="line", line=dict(dash="dash", color="red"),
          x0=min_val, x1=max_val, y0=min_val, y1=max_val
      )
      st.plotly_chart(fig_test, use_container_width=True)
  
  # æ®‹å·®åˆ†æ
  residuals_train = y_train - y_pred_train
  residuals_test = y_test - y_pred_test
  
  col1, col2 = st.columns(2)
  
  with col1:
      # æ®‹å·®vsé¢„æµ‹å€¼
      fig_resid = px.scatter(
          x=y_pred_test, y=residuals_test,
          title="æ®‹å·® vs é¢„æµ‹å€¼",
          labels={'x': 'é¢„æµ‹å€¼', 'y': 'æ®‹å·®'}
      )
      fig_resid.add_hline(y=0, line_dash="dash", line_color="red")
      st.plotly_chart(fig_resid, use_container_width=True)
  
  with col2:
      # æ®‹å·®åˆ†å¸ƒ
      fig_resid_hist = px.histogram(
          x=residuals_test,
          title="æ®‹å·®åˆ†å¸ƒ",
          labels={'x': 'æ®‹å·®', 'y': 'é¢‘æ•°'}
      )
      st.plotly_chart(fig_resid_hist, use_container_width=True)
  
  # ç‰¹å¾é‡è¦æ€§ï¼ˆå¦‚æœæ¨¡å‹æ”¯æŒï¼‰
  if hasattr(model, 'feature_importances_'):
      st.markdown("#### ç‰¹å¾é‡è¦æ€§")
      
      importance_df = pd.DataFrame({
          'ç‰¹å¾': feature_vars,
          'é‡è¦æ€§': model.feature_importances_
      }).sort_values('é‡è¦æ€§', ascending=False)
      
      fig_importance = px.bar(
          importance_df,
          x='é‡è¦æ€§',
          y='ç‰¹å¾',
          orientation='h',
          title="ç‰¹å¾é‡è¦æ€§æ’åº"
      )
      st.plotly_chart(fig_importance, use_container_width=True)
  
  elif hasattr(model, 'coef_'):
      st.markdown("#### å›å½’ç³»æ•°")
      
      coef_df = pd.DataFrame({
          'ç‰¹å¾': feature_vars,
          'ç³»æ•°': model.coef_
      })
      
      if hasattr(model, 'intercept_'):
          intercept_row = pd.DataFrame({'ç‰¹å¾': ['æˆªè·'], 'ç³»æ•°': [model.intercept_]})
          coef_df = pd.concat([intercept_row, coef_df], ignore_index=True)
      
      st.dataframe(coef_df.round(4), use_container_width=True)

def show_clustering_analysis(data: pd.DataFrame):
  """æ˜¾ç¤ºèšç±»åˆ†æ"""
  st.markdown('<h2 class="sub-header">èšç±»åˆ†æ</h2>', unsafe_allow_html=True)
  
  numeric_cols = data.select_dtypes(include=[np.number]).columns.tolist()
  
  if len(numeric_cols) < 2:
      st.warning("éœ€è¦è‡³å°‘2ä¸ªæ•°å€¼å˜é‡è¿›è¡Œèšç±»åˆ†æ")
      return
  
  # é€‰æ‹©ç‰¹å¾å˜é‡
  feature_vars = st.multiselect(
      "é€‰æ‹©ç”¨äºèšç±»çš„ç‰¹å¾å˜é‡",
      numeric_cols,
      default=numeric_cols[:4] if len(numeric_cols) >= 4 else numeric_cols
  )
  
  if len(feature_vars) < 2:
      st.warning("è¯·è‡³å°‘é€‰æ‹©2ä¸ªç‰¹å¾å˜é‡")
      return
  
  # é€‰æ‹©èšç±»ç®—æ³•
  algorithm = st.selectbox(
      "é€‰æ‹©èšç±»ç®—æ³•",
      ["K-means", "å±‚æ¬¡èšç±»", "DBSCAN"]
  )
  
  # æ•°æ®é¢„å¤„ç†
  st.markdown("### æ•°æ®é¢„å¤„ç†")
  
  col1, col2 = st.columns(2)
  
  with col1:
      handle_missing = st.selectbox(
          "ç¼ºå¤±å€¼å¤„ç†",
          ["åˆ é™¤ç¼ºå¤±å€¼", "å‡å€¼å¡«å……"],
          key="cluster_missing"
      )
  
  with col2:
      scale_features = st.checkbox("ç‰¹å¾æ ‡å‡†åŒ–", value=True, key="cluster_scale")
  
  # ç®—æ³•å‚æ•°
  if algorithm == "K-means":
      n_clusters = st.slider("èšç±»æ•°é‡", 2, 10, 3)
  elif algorithm == "å±‚æ¬¡èšç±»":
      n_clusters = st.slider("èšç±»æ•°é‡", 2, 10, 3)
      linkage = st.selectbox("é“¾æ¥æ–¹æ³•", ["ward", "complete", "average", "single"])
  elif algorithm == "DBSCAN":
      eps = st.slider("é‚»åŸŸåŠå¾„(eps)", 0.1, 2.0, 0.5, 0.1)
      min_samples = st.slider("æœ€å°æ ·æœ¬æ•°", 2, 20, 5)
  
  if st.button("æ‰§è¡Œèšç±»åˆ†æ"):
      try:
          # æ•°æ®å‡†å¤‡
          cluster_data = data[feature_vars].copy()
          
          # å¤„ç†ç¼ºå¤±å€¼
          if handle_missing == "åˆ é™¤ç¼ºå¤±å€¼":
              cluster_data = cluster_data.dropna()
          elif handle_missing == "å‡å€¼å¡«å……":
              cluster_data = cluster_data.fillna(cluster_data.mean())
          
          # ç‰¹å¾æ ‡å‡†åŒ–
          if scale_features:
              scaler = StandardScaler()
              X_scaled = scaler.fit_transform(cluster_data)
          else:
              X_scaled = cluster_data.values
          
          # é€‰æ‹©å’Œæ‰§è¡Œèšç±»ç®—æ³•
          if algorithm == "K-means":
              clusterer = KMeans(n_clusters=n_clusters, random_state=42)
              cluster_labels = clusterer.fit_predict(X_scaled)
          elif algorithm == "å±‚æ¬¡èšç±»":
              clusterer = AgglomerativeClustering(n_clusters=n_clusters, linkage=linkage)
              cluster_labels = clusterer.fit_predict(X_scaled)
          elif algorithm == "DBSCAN":
              clusterer = DBSCAN(eps=eps, min_samples=min_samples)
              cluster_labels = clusterer.fit_predict(X_scaled)
          
          # æ˜¾ç¤ºèšç±»ç»“æœ
          show_clustering_results(cluster_data, X_scaled, cluster_labels, feature_vars, algorithm)
          
      except Exception as e:
          st.error(f"èšç±»åˆ†æå¤±è´¥: {str(e)}")

def show_clustering_results(original_data, scaled_data, cluster_labels, feature_vars, algorithm):
  """æ˜¾ç¤ºèšç±»ç»“æœ"""
  st.markdown("### ğŸ¯ èšç±»åˆ†æç»“æœ")
  
  # åŸºæœ¬ç»Ÿè®¡
  n_clusters = len(np.unique(cluster_labels[cluster_labels >= 0]))  # æ’é™¤å™ªå£°ç‚¹(-1)
  n_noise = np.sum(cluster_labels == -1) if -1 in cluster_labels else 0
  
  col1, col2, col3 = st.columns(3)
  
  with col1:
      st.metric("èšç±»æ•°é‡", n_clusters)
  with col2:
      st.metric("æ ·æœ¬æ€»æ•°", len(cluster_labels))
  with col3:
      if n_noise > 0:
          st.metric("å™ªå£°ç‚¹æ•°é‡", n_noise)
      else:
          st.metric("å™ªå£°ç‚¹æ•°é‡", 0)
  
  # è½®å»“ç³»æ•°
  if n_clusters > 1 and len(np.unique(cluster_labels)) > 1:
      silhouette_avg = silhouette_score(scaled_data, cluster_labels)
      st.metric("å¹³å‡è½®å»“ç³»æ•°", f"{silhouette_avg:.4f}")
      
      if silhouette_avg > 0.7:
          st.success("âœ… èšç±»æ•ˆæœå¾ˆå¥½")
      elif silhouette_avg > 0.5:
          st.info("â„¹ï¸ èšç±»æ•ˆæœè¾ƒå¥½")
      elif silhouette_avg > 0.25:
          st.warning("âš ï¸ èšç±»æ•ˆæœä¸€èˆ¬")
      else:
          st.error("âŒ èšç±»æ•ˆæœè¾ƒå·®")
  
  # èšç±»å¯è§†åŒ–
  if len(feature_vars) >= 2:
      # æ·»åŠ èšç±»æ ‡ç­¾åˆ°åŸå§‹æ•°æ®
      plot_data = original_data.copy()
      plot_data['èšç±»'] = cluster_labels
      
      # 2Dæ•£ç‚¹å›¾
      fig_2d = px.scatter(
          plot_data,
          x=feature_vars[0],
          y=feature_vars[1],
          color='èšç±»',
          title=f"èšç±»ç»“æœ ({feature_vars[0]} vs {feature_vars[1]})",
          color_continuous_scale='viridis'
      )
      st.plotly_chart(fig_2d, use_container_width=True)
      
      # 3Dæ•£ç‚¹å›¾ï¼ˆå¦‚æœæœ‰3ä¸ªæˆ–æ›´å¤šç‰¹å¾ï¼‰
      if len(feature_vars) >= 3:
          fig_3d = px.scatter_3d(
              plot_data,
              x=feature_vars[0],
              y=feature_vars[1],
              z=feature_vars[2],
              color='èšç±»',
              title=f"3Dèšç±»ç»“æœ",
              color_continuous_scale='viridis'
          )
          st.plotly_chart(fig_3d, use_container_width=True)
  
  # èšç±»ä¸­å¿ƒç»Ÿè®¡ï¼ˆK-meansï¼‰
  if algorithm == "K-means":
      st.markdown("### èšç±»ä¸­å¿ƒç‰¹å¾")
      
      cluster_centers = []
      for i in range(n_clusters):
          cluster_mask = cluster_labels == i
          cluster_center = original_data[cluster_mask].mean()
          cluster_centers.append(cluster_center)
      
      centers_df = pd.DataFrame(cluster_centers, 
                              index=[f'èšç±»{i}' for i in range(n_clusters)],
                              columns=feature_vars)
      st.dataframe(centers_df.round(4), use_container_width=True)
  
  # å„èšç±»çš„æ ·æœ¬æ•°é‡
  st.markdown("### èšç±»åˆ†å¸ƒ")
  
  cluster_counts = pd.Series(cluster_labels).value_counts().sort_index()
  
  fig_dist = px.bar(
      x=cluster_counts.index,
      y=cluster_counts.values,
      title="å„èšç±»æ ·æœ¬æ•°é‡",
      labels={'x': 'èšç±»æ ‡ç­¾', 'y': 'æ ·æœ¬æ•°é‡'}
  )
  st.plotly_chart(fig_dist, use_container_width=True)

def show_model_evaluation(data: pd.DataFrame):
  """æ˜¾ç¤ºæ¨¡å‹è¯„ä¼°"""
  st.markdown('<h2 class="sub-header">æ¨¡å‹è¯„ä¼°ä¸æ¯”è¾ƒ</h2>', unsafe_allow_html=True)
  
  # æ£€æŸ¥æ˜¯å¦æœ‰å·²è®­ç»ƒçš„æ¨¡å‹
  if 'trained_model' not in st.session_state:
      st.warning("âš ï¸ è¯·å…ˆè®­ç»ƒä¸€ä¸ªæ¨¡å‹")
      return
  
  model_info = st.session_state.trained_model
  
  st.markdown("### ğŸ“‹ å·²è®­ç»ƒæ¨¡å‹ä¿¡æ¯")
  
  col1, col2, col3 = st.columns(3)
  
  with col1:
      st.info(f"**ç®—æ³•**: {model_info['algorithm']}")
  with col2:
      st.info(f"**ç›®æ ‡å˜é‡**: {model_info['target_var']}")
  with col3:
      st.info(f"**ç‰¹å¾æ•°é‡**: {len(model_info['feature_vars'])}")
  
  # äº¤å‰éªŒè¯
  st.markdown("### ğŸ”„ äº¤å‰éªŒè¯")
  
  cv_folds = st.slider("äº¤å‰éªŒè¯æŠ˜æ•°", 3, 10, 5)
  
  if st.button("æ‰§è¡Œäº¤å‰éªŒè¯"):
      try:
          # å‡†å¤‡æ•°æ®
          feature_vars = model_info['feature_vars']
          target_var = model_info['target_var']
          
          model_data = data[[target_var] + feature_vars].dropna()
          
          # ç¼–ç å¤„ç†ï¼ˆå¦‚æœéœ€è¦ï¼‰
          if model_info['le_dict']:
              for col, le in model_info['le_dict'].items():
                  if col in model_data.columns:
                      model_data[col] = le.transform(model_data[col].astype(str))
          
          X = model_data[feature_vars]
          y = model_data[target_var]
          
          # æ ‡å‡†åŒ–ï¼ˆå¦‚æœéœ€è¦ï¼‰
          if model_info['scaler']:
              X_scaled = model_info['scaler'].fit_transform(X)
          else:
              X_scaled = X.values
          
          # æ‰§è¡Œäº¤å‰éªŒè¯
          model = model_info['model']
          
          if hasattr(model, 'predict_proba'):  # åˆ†ç±»æ¨¡å‹
              cv_scores = cross_val_score(model, X_scaled, y, cv=cv_folds, scoring='accuracy')
              metric_name = "å‡†ç¡®ç‡"
          else:  # å›å½’æ¨¡å‹
              cv_scores = cross_val_score(model, X_scaled, y, cv=cv_folds, scoring='r2')
              metric_name = "RÂ²"
          
          # æ˜¾ç¤ºäº¤å‰éªŒè¯ç»“æœ
          col1, col2, col3 = st.columns(3)
          
          with col1:
              st.metric(f"å¹³å‡{metric_name}", f"{cv_scores.mean():.4f}")
          with col2:
              st.metric("æ ‡å‡†å·®", f"{cv_scores.std():.4f}")
          with col3:
              st.metric("95%ç½®ä¿¡åŒºé—´", f"Â±{1.96 * cv_scores.std():.4f}")
          
          # äº¤å‰éªŒè¯åˆ†æ•°åˆ†å¸ƒ
          fig_cv = px.box(
              y=cv_scores,
              title=f"äº¤å‰éªŒè¯{metric_name}åˆ†å¸ƒ"
          )
          st.plotly_chart(fig_cv, use_container_width=True)
          
      except Exception as e:
          st.error(f"äº¤å‰éªŒè¯å¤±è´¥: {str(e)}")
  
  # æ¨¡å‹é¢„æµ‹
  st.markdown("### ğŸ”® æ¨¡å‹é¢„æµ‹")
  
  st.write("è¾“å…¥ç‰¹å¾å€¼è¿›è¡Œé¢„æµ‹ï¼š")
  
  feature_vars = model_info['feature_vars']
  input_values = {}
  
  cols = st.columns(min(3, len(feature_vars)))
  
  for i, feature in enumerate(feature_vars):
      with cols[i % 3]:
          # è·å–è¯¥ç‰¹å¾çš„ç»Ÿè®¡ä¿¡æ¯
          feature_data = data[feature].dropna()
          min_val = float(feature_data.min())
          max_val = float(feature_data.max())
          mean_val = float(feature_data.mean())
          
          input_values[feature] = st.number_input(
              f"{feature}",
              min_value=min_val,
              max_value=max_val,
              value=mean_val,
              key=f"predict_{feature}"
          )
  
  if st.button("è¿›è¡Œé¢„æµ‹"):
      try:
          # å‡†å¤‡è¾“å…¥æ•°æ®
          input_df = pd.DataFrame([input_values])
          
          # æ ‡å‡†åŒ–ï¼ˆå¦‚æœéœ€è¦ï¼‰
          if model_info['scaler']:
              input_scaled = model_info['scaler'].transform(input_df)
          else:
              input_scaled = input_df.values
          
          # é¢„æµ‹
          model = model_info['model']
          prediction = model.predict(input_scaled)[0]
          
          st.success(f"ğŸ¯ é¢„æµ‹ç»“æœ: {prediction:.4f}")
          
          # å¦‚æœæ˜¯åˆ†ç±»æ¨¡å‹ï¼Œæ˜¾ç¤ºæ¦‚ç‡
          if hasattr(model, 'predict_proba'):
              probabilities = model.predict_proba(input_scaled)[0]
              
              st.markdown("#### é¢„æµ‹æ¦‚ç‡")
              
              prob_df = pd.DataFrame({
                  'ç±»åˆ«': model.classes_,
                  'æ¦‚ç‡': probabilities
              })
              
              fig_prob = px.bar(
                  prob_df,
                  x='ç±»åˆ«',
                  y='æ¦‚ç‡',
                  title="å„ç±»åˆ«é¢„æµ‹æ¦‚ç‡"
              )
              st.plotly_chart(fig_prob, use_container_width=True)
          
      except Exception as e:
          st.error(f"é¢„æµ‹å¤±è´¥: {str(e)}")
