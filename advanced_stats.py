import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from core.statistical_methods import InferentialStatistics, NonParametricTests, EffectSizeCalculator
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.metrics import r2_score, classification_report
import seaborn as sns

def show():
  """æ˜¾ç¤ºé«˜çº§ç»Ÿè®¡åˆ†æé¡µé¢"""
  st.markdown('<h1 class="main-header">ğŸ”¬ é«˜çº§ç»Ÿè®¡åˆ†æ</h1>', unsafe_allow_html=True)
  
  if st.session_state.data is None:
      st.warning("âš ï¸ è¯·å…ˆåœ¨æ•°æ®å¯¼å…¥é¡µé¢åŠ è½½æ•°æ®")
      return
  
  data = st.session_state.data
  
  # åˆ›å»ºæ ‡ç­¾é¡µ
  tab1, tab2, tab3, tab4, tab5 = st.tabs([
      "å‡è®¾æ£€éªŒ", "å›å½’åˆ†æ", "éå‚æ•°æ£€éªŒ", "æ•ˆåº”é‡åˆ†æ", "å¤šå˜é‡åˆ†æ"
  ])
  
  with tab1:
      show_hypothesis_testing(data)
  
  with tab2:
      show_regression_analysis(data)
  
  with tab3:
      show_nonparametric_tests(data)
  
  with tab4:
      show_effect_size_analysis(data)
  
  with tab5:
      show_multivariate_analysis(data)

def show_hypothesis_testing(data: pd.DataFrame):
  """æ˜¾ç¤ºå‡è®¾æ£€éªŒ"""
  st.markdown('<h2 class="sub-header">å‡è®¾æ£€éªŒ</h2>', unsafe_allow_html=True)
  
  test_type = st.selectbox(
      "é€‰æ‹©æ£€éªŒç±»å‹",
      ["å•æ ·æœ¬tæ£€éªŒ", "ç‹¬ç«‹æ ·æœ¬tæ£€éªŒ", "é…å¯¹æ ·æœ¬tæ£€éªŒ", "å¡æ–¹æ£€éªŒ", "å•å› ç´ æ–¹å·®åˆ†æ"]
  )
  
  inferential_stats = InferentialStatistics()
  
  if test_type == "å•æ ·æœ¬tæ£€éªŒ":
      show_one_sample_ttest(data, inferential_stats)
  elif test_type == "ç‹¬ç«‹æ ·æœ¬tæ£€éªŒ":
      show_two_sample_ttest(data, inferential_stats)
  elif test_type == "é…å¯¹æ ·æœ¬tæ£€éªŒ":
      show_paired_ttest(data, inferential_stats)
  elif test_type == "å¡æ–¹æ£€éªŒ":
      show_chi_square_test(data, inferential_stats)
  elif test_type == "å•å› ç´ æ–¹å·®åˆ†æ":
      show_anova_test(data, inferential_stats)

def show_one_sample_ttest(data: pd.DataFrame, inferential_stats: InferentialStatistics):
  """å•æ ·æœ¬tæ£€éªŒ"""
  st.markdown("### å•æ ·æœ¬tæ£€éªŒ")
  
  numeric_cols = data.select_dtypes(include=[np.number]).columns.tolist()
  
  if not numeric_cols:
      st.warning("æ²¡æœ‰æ•°å€¼å˜é‡å¯è¿›è¡Œæ£€éªŒ")
      return
  
  col1, col2 = st.columns(2)
  
  with col1:
      test_var = st.selectbox("é€‰æ‹©æ£€éªŒå˜é‡", numeric_cols)
  
  with col2:
      test_value = st.number_input("æ£€éªŒå€¼ï¼ˆÎ¼â‚€ï¼‰", value=0.0)
  
  if st.button("æ‰§è¡Œæ£€éªŒ"):
      result = inferential_stats.one_sample_ttest(data[test_var], test_value)
      
      # æ˜¾ç¤ºç»“æœ
      col1, col2, col3 = st.columns(3)
      
      with col1:
          st.metric("tç»Ÿè®¡é‡", f"{result['statistic']:.4f}")
      with col2:
          st.metric("på€¼", f"{result['p_value']:.4f}")
      with col3:
          st.metric("è‡ªç”±åº¦", result['degrees_of_freedom'])
      
      # ç»“æœè§£é‡Š
      if result['significant']:
          st.success(f"âœ… {result['interpretation']}")
      else:
          st.info(f"â„¹ï¸ {result['interpretation']}")
      
      # å¯è§†åŒ–
      fig = create_ttest_visualization(data[test_var], test_value, result)
      st.plotly_chart(fig, use_container_width=True)

def show_two_sample_ttest(data: pd.DataFrame, inferential_stats: InferentialStatistics):
  """ç‹¬ç«‹æ ·æœ¬tæ£€éªŒ"""
  st.markdown("### ç‹¬ç«‹æ ·æœ¬tæ£€éªŒ")
  
  numeric_cols = data.select_dtypes(include=[np.number]).columns.tolist()
  categorical_cols = data.select_dtypes(include=['object', 'category']).columns.tolist()
  
  if not numeric_cols or not categorical_cols:
      st.warning("éœ€è¦è‡³å°‘ä¸€ä¸ªæ•°å€¼å˜é‡å’Œä¸€ä¸ªåˆ†ç±»å˜é‡")
      return
  
  col1, col2 = st.columns(2)
  
  with col1:
      test_var = st.selectbox("é€‰æ‹©æ£€éªŒå˜é‡", numeric_cols)
  
  with col2:
      group_var = st.selectbox("é€‰æ‹©åˆ†ç»„å˜é‡", categorical_cols)
  
  # æ£€æŸ¥åˆ†ç»„å˜é‡çš„å”¯ä¸€å€¼
  unique_groups = data[group_var].dropna().unique()
  
  if len(unique_groups) != 2:
      st.warning(f"åˆ†ç»„å˜é‡å¿…é¡»æ°å¥½æœ‰2ä¸ªç±»åˆ«ï¼Œå½“å‰æœ‰{len(unique_groups)}ä¸ª")
      return
  
  equal_var = st.checkbox("å‡è®¾ç­‰æ–¹å·®", value=True)
  
  if st.button("æ‰§è¡Œæ£€éªŒ"):
      group1_data = data[data[group_var] == unique_groups[0]][test_var]
      group2_data = data[data[group_var] == unique_groups[1]][test_var]
      
      result = inferential_stats.two_sample_ttest(group1_data, group2_data, equal_var)
      
      # æ˜¾ç¤ºç»“æœ
      col1, col2 = st.columns(2)
      
      with col1:
          st.metric("tç»Ÿè®¡é‡", f"{result['statistic']:.4f}")
          st.metric(f"{unique_groups[0]} å‡å€¼", f"{result['group1_mean']:.4f}")
          st.metric(f"{unique_groups[0]} æ ‡å‡†å·®", f"{result['group1_std']:.4f}")
      
      with col2:
          st.metric("på€¼", f"{result['p_value']:.4f}")
          st.metric(f"{unique_groups[1]} å‡å€¼", f"{result['group2_mean']:.4f}")
          st.metric(f"{unique_groups[1]} æ ‡å‡†å·®", f"{result['group2_std']:.4f}")
      
      # ç»“æœè§£é‡Š
      if result['significant']:
          st.success(f"âœ… {result['interpretation']}")
      else:
          st.info(f"â„¹ï¸ {result['interpretation']}")
      
      # æ•ˆåº”é‡
      effect_size = EffectSizeCalculator.cohens_d(group1_data, group2_data)
      st.metric("Cohen's d", f"{effect_size:.4f}")
      st.info(f"æ•ˆåº”é‡: {EffectSizeCalculator.interpret_cohens_d(effect_size)}")

def show_regression_analysis(data: pd.DataFrame):
  """æ˜¾ç¤ºå›å½’åˆ†æ"""
  st.markdown('<h2 class="sub-header">å›å½’åˆ†æ</h2>', unsafe_allow_html=True)
  
  regression_type = st.selectbox(
      "é€‰æ‹©å›å½’ç±»å‹",
      ["çº¿æ€§å›å½’", "å¤šå…ƒçº¿æ€§å›å½’", "é€»è¾‘å›å½’"]
  )
  
  if regression_type == "çº¿æ€§å›å½’":
      show_simple_linear_regression(data)
  elif regression_type == "å¤šå…ƒçº¿æ€§å›å½’":
      show_multiple_linear_regression(data)
  elif regression_type == "é€»è¾‘å›å½’":
      show_logistic_regression(data)

def show_simple_linear_regression(data: pd.DataFrame):
  """ç®€å•çº¿æ€§å›å½’"""
  st.markdown("### ç®€å•çº¿æ€§å›å½’")
  
  numeric_cols = data.select_dtypes(include=[np.number]).columns.tolist()
  
  if len(numeric_cols) < 2:
      st.warning("éœ€è¦è‡³å°‘2ä¸ªæ•°å€¼å˜é‡è¿›è¡Œå›å½’åˆ†æ")
      return
  
  col1, col2 = st.columns(2)
  
  with col1:
      y_var = st.selectbox("é€‰æ‹©å› å˜é‡ (Y)", numeric_cols)
  
  with col2:
      x_var = st.selectbox("é€‰æ‹©è‡ªå˜é‡ (X)", [col for col in numeric_cols if col != y_var])
  
  if st.button("æ‰§è¡Œå›å½’åˆ†æ"):
      # å‡†å¤‡æ•°æ®
      mask = ~(data[x_var].isna() | data[y_var].isna())
      X = data[x_var][mask].values.reshape(-1, 1)
      y = data[y_var][mask].values
      
      # æ‹Ÿåˆæ¨¡å‹
      model = LinearRegression()
      model.fit(X, y)
      
      # é¢„æµ‹
      y_pred = model.predict(X)
      
      # è®¡ç®—ç»Ÿè®¡é‡
      r2 = r2_score(y, y_pred)
      correlation = np.corrcoef(X.flatten(), y)[0, 1]
      
      # æ˜¾ç¤ºç»“æœ
      col1, col2, col3 = st.columns(3)
      
      with col1:
          st.metric("RÂ²", f"{r2:.4f}")
      with col2:
          st.metric("ç›¸å…³ç³»æ•°", f"{correlation:.4f}")
      with col3:
          st.metric("å›å½’ç³»æ•°", f"{model.coef_[0]:.4f}")
      
      st.metric("æˆªè·", f"{model.intercept_:.4f}")
      
      # å›å½’æ–¹ç¨‹
      st.markdown("### å›å½’æ–¹ç¨‹")
      equation = f"{y_var} = {model.intercept_:.4f} + {model.coef_[0]:.4f} Ã— {x_var}"
      st.latex(equation.replace('Ã—', r'\times'))
      
      # å¯è§†åŒ–
      fig = px.scatter(data, x=x_var, y=y_var, title=f"{y_var} vs {x_var}")
      
      # æ·»åŠ å›å½’çº¿
      x_range = np.linspace(X.min(), X.max(), 100).reshape(-1, 1)
      y_range = model.predict(x_range)
      
      fig.add_scatter(
          x=x_range.flatten(),
          y=y_range,
          mode='lines',
          name='å›å½’çº¿',
          line=dict(color='red')
      )
      
      st.plotly_chart(fig, use_container_width=True)

def show_multiple_linear_regression(data: pd.DataFrame):
  """å¤šå…ƒçº¿æ€§å›å½’"""
  st.markdown("### å¤šå…ƒçº¿æ€§å›å½’")
  
  numeric_cols = data.select_dtypes(include=[np.number]).columns.tolist()
  
  if len(numeric_cols) < 3:
      st.warning("éœ€è¦è‡³å°‘3ä¸ªæ•°å€¼å˜é‡è¿›è¡Œå¤šå…ƒå›å½’åˆ†æ")
      return
  
  y_var = st.selectbox("é€‰æ‹©å› å˜é‡ (Y)", numeric_cols)
  x_vars = st.multiselect(
      "é€‰æ‹©è‡ªå˜é‡ (X)",
      [col for col in numeric_cols if col != y_var],
      default=[col for col in numeric_cols if col != y_var][:3]
  )
  
  if len(x_vars) < 1:
      st.warning("è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªè‡ªå˜é‡")
      return
  
  if st.button("æ‰§è¡Œå¤šå…ƒå›å½’åˆ†æ"):
      # å‡†å¤‡æ•°æ®
      vars_to_use = [y_var] + x_vars
      clean_data = data[vars_to_use].dropna()
      
      X = clean_data[x_vars].values
      y = clean_data[y_var].values
      
      # æ‹Ÿåˆæ¨¡å‹
      model = LinearRegression()
      model.fit(X, y)
      
      # é¢„æµ‹
      y_pred = model.predict(X)
      
      # è®¡ç®—ç»Ÿè®¡é‡
      r2 = r2_score(y, y_pred)
      adj_r2 = 1 - (1 - r2) * (len(y) - 1) / (len(y) - len(x_vars) - 1)
      
      # æ˜¾ç¤ºç»“æœ
      col1, col2, col3 = st.columns(3)
      
      with col1:
          st.metric("RÂ²", f"{r2:.4f}")
      with col2:
          st.metric("è°ƒæ•´RÂ²", f"{adj_r2:.4f}")
      with col3:
          st.metric("æ ·æœ¬é‡", len(y))
      
      # å›å½’ç³»æ•°è¡¨
      st.markdown("### å›å½’ç³»æ•°")
      
      coef_df = pd.DataFrame({
          'å˜é‡': ['æˆªè·'] + x_vars,
          'ç³»æ•°': [model.intercept_] + model.coef_.tolist(),
          'æ ‡å‡†åŒ–ç³»æ•°': [0] + (model.coef_ * np.std(X, axis=0) / np.std(y)).tolist()
      })
      
      st.dataframe(coef_df.round(4), use_container_width=True)
      
      # æ®‹å·®åˆ†æ
      residuals = y - y_pred
      
      col1, col2 = st.columns(2)
      
      with col1:
          # æ®‹å·®vsæ‹Ÿåˆå€¼å›¾
          fig_resid = px.scatter(
              x=y_pred, y=residuals,
              title="æ®‹å·® vs æ‹Ÿåˆå€¼",
              labels={'x': 'æ‹Ÿåˆå€¼', 'y': 'æ®‹å·®'}
          )
          fig_resid.add_hline(y=0, line_dash="dash", line_color="red")
          st.plotly_chart(fig_resid, use_container_width=True)
      
      with col2:
          # æ®‹å·®ç›´æ–¹å›¾
          fig_hist = px.histogram(
              x=residuals,
              title="æ®‹å·®åˆ†å¸ƒ",
              labels={'x': 'æ®‹å·®', 'y': 'é¢‘æ•°'}
          )
          st.plotly_chart(fig_hist, use_container_width=True)

def show_nonparametric_tests(data: pd.DataFrame):
  """æ˜¾ç¤ºéå‚æ•°æ£€éªŒ"""
  st.markdown('<h2 class="sub-header">éå‚æ•°æ£€éªŒ</h2>', unsafe_allow_html=True)
  
  test_type = st.selectbox(
      "é€‰æ‹©éå‚æ•°æ£€éªŒç±»å‹",
      ["Mann-Whitney Uæ£€éªŒ", "Wilcoxonç¬¦å·ç§©æ£€éªŒ", "Kruskal-Wallisæ£€éªŒ"]
  )
  
  nonparam_tests = NonParametricTests()
  
  if test_type == "Mann-Whitney Uæ£€éªŒ":
      show_mann_whitney_test(data, nonparam_tests)
  elif test_type == "Wilcoxonç¬¦å·ç§©æ£€éªŒ":
      show_wilcoxon_test(data, nonparam_tests)
  elif test_type == "Kruskal-Wallisæ£€éªŒ":
      show_kruskal_wallis_test(data, nonparam_tests)

def show_mann_whitney_test(data: pd.DataFrame, nonparam_tests: NonParametricTests):
  """Mann-Whitney Uæ£€éªŒ"""
  st.markdown("### Mann-Whitney Uæ£€éªŒ")
  st.info("ğŸ’¡ ç”¨äºæ¯”è¾ƒä¸¤ä¸ªç‹¬ç«‹ç»„çš„ä¸­ä½æ•°å·®å¼‚ï¼ˆéå‚æ•°ç‰ˆæœ¬çš„ç‹¬ç«‹æ ·æœ¬tæ£€éªŒï¼‰")
  
  numeric_cols = data.select_dtypes(include=[np.number]).columns.tolist()
  categorical_cols = data.select_dtypes(include=['object', 'category']).columns.tolist()
  
  if not numeric_cols or not categorical_cols:
      st.warning("éœ€è¦è‡³å°‘ä¸€ä¸ªæ•°å€¼å˜é‡å’Œä¸€ä¸ªåˆ†ç±»å˜é‡")
      return
  
  col1, col2 = st.columns(2)
  
  with col1:
      test_var = st.selectbox("é€‰æ‹©æ£€éªŒå˜é‡", numeric_cols)
  
  with col2:
      group_var = st.selectbox("é€‰æ‹©åˆ†ç»„å˜é‡", categorical_cols)
  
  # æ£€æŸ¥åˆ†ç»„å˜é‡çš„å”¯ä¸€å€¼
  unique_groups = data[group_var].dropna().unique()
  
  if len(unique_groups) != 2:
      st.warning(f"åˆ†ç»„å˜é‡å¿…é¡»æ°å¥½æœ‰2ä¸ªç±»åˆ«ï¼Œå½“å‰æœ‰{len(unique_groups)}ä¸ª")
      return
  
  if st.button("æ‰§è¡ŒMann-Whitney Uæ£€éªŒ"):
      group1_data = data[data[group_var] == unique_groups[0]][test_var]
      group2_data = data[data[group_var] == unique_groups[1]][test_var]
      
      result = nonparam_tests.mann_whitney_u_test(group1_data, group2_data)
      
      # æ˜¾ç¤ºç»“æœ
      col1, col2, col3 = st.columns(3)
      
      with col1:
          st.metric("Uç»Ÿè®¡é‡", f"{result['u_statistic']:.0f}")
      with col2:
          st.metric("på€¼", f"{result['p_value']:.4f}")
      with col3:
          if result['significant']:
              st.success("âœ… æ˜¾è‘—")
          else:
              st.info("â„¹ï¸ ä¸æ˜¾è‘—")
      
      # ç»„åˆ«ç»Ÿè®¡
      st.markdown("### ç»„åˆ«ç»Ÿè®¡")
      
      group_stats = pd.DataFrame({
          'ç»„åˆ«': [unique_groups[0], unique_groups[1]],
          'æ ·æœ¬é‡': [result['group1_size'], result['group2_size']],
          'ä¸­ä½æ•°': [result['group1_median'], result['group2_median']]
      })
      
      st.dataframe(group_stats, use_container_width=True)
      
      # ç»“æœè§£é‡Š
      st.markdown("### æ£€éªŒç»“æœ")
      st.write(result['interpretation'])
      
      # å¯è§†åŒ–
      fig = create_group_comparison_plot(data, test_var, group_var, "Mann-Whitney Uæ£€éªŒç»“æœ")
      st.plotly_chart(fig, use_container_width=True)

def show_wilcoxon_test(data: pd.DataFrame, nonparam_tests: NonParametricTests):
  """Wilcoxonç¬¦å·ç§©æ£€éªŒ"""
  st.markdown("### Wilcoxonç¬¦å·ç§©æ£€éªŒ")
  st.info("ğŸ’¡ ç”¨äºæ¯”è¾ƒé…å¯¹æ ·æœ¬çš„ä¸­ä½æ•°å·®å¼‚ï¼ˆéå‚æ•°ç‰ˆæœ¬çš„é…å¯¹tæ£€éªŒï¼‰")
  
  numeric_cols = data.select_dtypes(include=[np.number]).columns.tolist()
  
  if len(numeric_cols) < 2:
      st.warning("éœ€è¦è‡³å°‘2ä¸ªæ•°å€¼å˜é‡è¿›è¡Œé…å¯¹æ£€éªŒ")
      return
  
  col1, col2 = st.columns(2)
  
  with col1:
      before_var = st.selectbox("é€‰æ‹©å‰æµ‹å˜é‡", numeric_cols)
  
  with col2:
      after_var = st.selectbox("é€‰æ‹©åæµ‹å˜é‡", [col for col in numeric_cols if col != before_var])
  
  if st.button("æ‰§è¡ŒWilcoxonç¬¦å·ç§©æ£€éªŒ"):
      result = nonparam_tests.wilcoxon_signed_rank_test(data[before_var], data[after_var])
      
      # æ˜¾ç¤ºç»“æœ
      col1, col2, col3 = st.columns(3)
      
      with col1:
          st.metric("Wç»Ÿè®¡é‡", f"{result['w_statistic']:.0f}")
      with col2:
          st.metric("på€¼", f"{result['p_value']:.4f}")
      with col3:
          st.metric("æ ·æœ¬é‡", result['sample_size'])
      
      # å‰åæµ‹ç»Ÿè®¡
      col1, col2 = st.columns(2)
      
      with col1:
          st.metric(f"{before_var} ä¸­ä½æ•°", f"{result['before_median']:.4f}")
      with col2:
          st.metric(f"{after_var} ä¸­ä½æ•°", f"{result['after_median']:.4f}")
      
      # ç»“æœè§£é‡Š
      if result['significant']:
          st.success(f"âœ… {result['interpretation']}")
      else:
          st.info(f"â„¹ï¸ {result['interpretation']}")
      
      # å·®å€¼åˆ†æ
      differences = data[after_var] - data[before_var]
      differences_clean = differences.dropna()
      
      st.markdown("### å·®å€¼åˆ†æ")
      
      col1, col2, col3 = st.columns(3)
      
      with col1:
          st.metric("æ”¹å–„ä¾‹æ•°", (differences_clean > 0).sum())
      with col2:
          st.metric("æ¶åŒ–ä¾‹æ•°", (differences_clean < 0).sum())
      with col3:
          st.metric("æ— å˜åŒ–ä¾‹æ•°", (differences_clean == 0).sum())

def show_effect_size_analysis(data: pd.DataFrame):
  """æ˜¾ç¤ºæ•ˆåº”é‡åˆ†æ"""
  st.markdown('<h2 class="sub-header">æ•ˆåº”é‡åˆ†æ</h2>', unsafe_allow_html=True)
  
  st.info("ğŸ’¡ æ•ˆåº”é‡ç”¨äºè¡¡é‡ç»Ÿè®¡æ˜¾è‘—æ€§çš„å®é™…æ„ä¹‰å¤§å°")
  
  effect_type = st.selectbox(
      "é€‰æ‹©æ•ˆåº”é‡ç±»å‹",
      ["Cohen's d", "ç›¸å…³ç³»æ•°çš„å†³å®šç³»æ•°", "Etaå¹³æ–¹"]
  )
  
  if effect_type == "Cohen's d":
      show_cohens_d_analysis(data)
  elif effect_type == "ç›¸å…³ç³»æ•°çš„å†³å®šç³»æ•°":
      show_r_squared_analysis(data)
  elif effect_type == "Etaå¹³æ–¹":
      show_eta_squared_analysis(data)

def show_cohens_d_analysis(data: pd.DataFrame):
  """Cohen's dåˆ†æ"""
  st.markdown("### Cohen's d æ•ˆåº”é‡åˆ†æ")
  
  numeric_cols = data.select_dtypes(include=[np.number]).columns.tolist()
  categorical_cols = data.select_dtypes(include=['object', 'category']).columns.tolist()
  
  if not numeric_cols or not categorical_cols:
      st.warning("éœ€è¦è‡³å°‘ä¸€ä¸ªæ•°å€¼å˜é‡å’Œä¸€ä¸ªåˆ†ç±»å˜é‡")
      return
  
  col1, col2 = st.columns(2)
  
  with col1:
      test_var = st.selectbox("é€‰æ‹©æ£€éªŒå˜é‡", numeric_cols, key="cohens_d_var")
  
  with col2:
      group_var = st.selectbox("é€‰æ‹©åˆ†ç»„å˜é‡", categorical_cols, key="cohens_d_group")
  
  unique_groups = data[group_var].dropna().unique()
  
  if len(unique_groups) != 2:
      st.warning(f"åˆ†ç»„å˜é‡å¿…é¡»æ°å¥½æœ‰2ä¸ªç±»åˆ«")
      return
  
  if st.button("è®¡ç®—Cohen's d"):
      group1_data = data[data[group_var] == unique_groups[0]][test_var].dropna()
      group2_data = data[data[group_var] == unique_groups[1]][test_var].dropna()
      
      cohens_d = EffectSizeCalculator.cohens_d(group1_data, group2_data)
      interpretation = EffectSizeCalculator.interpret_cohens_d(cohens_d)
      
      # æ˜¾ç¤ºç»“æœ
      col1, col2 = st.columns(2)
      
      with col1:
          st.metric("Cohen's d", f"{cohens_d:.4f}")
      with col2:
          st.info(f"æ•ˆåº”é‡å¤§å°: {interpretation}")
      
      # æ•ˆåº”é‡è§£é‡Šè¡¨
      st.markdown("### Cohen's d è§£é‡Šæ ‡å‡†")
      
      interpretation_df = pd.DataFrame({
          'æ•ˆåº”é‡èŒƒå›´': ['|d| < 0.2', '0.2 â‰¤ |d| < 0.5', '0.5 â‰¤ |d| < 0.8', '|d| â‰¥ 0.8'],
          'æ•ˆåº”å¤§å°': ['æ— æ•ˆåº”æˆ–æå°', 'å°æ•ˆåº”', 'ä¸­ç­‰æ•ˆåº”', 'å¤§æ•ˆåº”'],
          'å®é™…æ„ä¹‰': ['å‡ ä¹æ— å·®å¼‚', 'è¾ƒå°å·®å¼‚', 'ä¸­ç­‰å·®å¼‚', 'å¾ˆå¤§å·®å¼‚']
      })
      
      st.dataframe(interpretation_df, use_container_width=True)

def show_multivariate_analysis(data: pd.DataFrame):
  """æ˜¾ç¤ºå¤šå˜é‡åˆ†æ"""
  st.markdown('<h2 class="sub-header">å¤šå˜é‡åˆ†æ</h2>', unsafe_allow_html=True)
  
  analysis_type = st.selectbox(
      "é€‰æ‹©åˆ†æç±»å‹",
      ["ä¸»æˆåˆ†åˆ†æ(PCA)", "å› å­åˆ†æ", "èšç±»åˆ†æ", "åˆ¤åˆ«åˆ†æ"]
  )
  
  if analysis_type == "ä¸»æˆåˆ†åˆ†æ(PCA)":
      show_pca_analysis(data)
  elif analysis_type == "å› å­åˆ†æ":
      show_factor_analysis(data)
  elif analysis_type == "èšç±»åˆ†æ":
      show_cluster_analysis(data)
  elif analysis_type == "åˆ¤åˆ«åˆ†æ":
      show_discriminant_analysis(data)

def show_pca_analysis(data: pd.DataFrame):
  """ä¸»æˆåˆ†åˆ†æ"""
  st.markdown("### ä¸»æˆåˆ†åˆ†æ (PCA)")
  
  numeric_cols = data.select_dtypes(include=[np.number]).columns.tolist()
  
  if len(numeric_cols) < 3:
      st.warning("éœ€è¦è‡³å°‘3ä¸ªæ•°å€¼å˜é‡è¿›è¡ŒPCAåˆ†æ")
      return
  
  selected_vars = st.multiselect(
      "é€‰æ‹©ç”¨äºPCAçš„å˜é‡",
      numeric_cols,
      default=numeric_cols
  )
  
  if len(selected_vars) < 3:
      st.warning("è¯·è‡³å°‘é€‰æ‹©3ä¸ªå˜é‡")
      return
  
  standardize = st.checkbox("æ ‡å‡†åŒ–æ•°æ®", value=True)
  
  if st.button("æ‰§è¡ŒPCAåˆ†æ"):
      from sklearn.decomposition import PCA
      from sklearn.preprocessing import StandardScaler
      
      # å‡†å¤‡æ•°æ®
      pca_data = data[selected_vars].dropna()
      
      if standardize:
          scaler = StandardScaler()
          pca_data_scaled = scaler.fit_transform(pca_data)
      else:
          pca_data_scaled = pca_data.values
      
      # æ‰§è¡ŒPCA
      pca = PCA()
      pca_result = pca.fit_transform(pca_data_scaled)
      
      # æ–¹å·®è§£é‡Šæ¯”ä¾‹
      explained_variance_ratio = pca.explained_variance_ratio_
      cumulative_variance = np.cumsum(explained_variance_ratio)
      
      # æ˜¾ç¤ºç»“æœ
      st.markdown("### PCAç»“æœ")
      
      # æ–¹å·®è§£é‡Šè¡¨
      pca_summary = pd.DataFrame({
          'ä¸»æˆåˆ†': [f'PC{i+1}' for i in range(len(explained_variance_ratio))],
          'ç‰¹å¾å€¼': pca.explained_variance_,
          'æ–¹å·®è§£é‡Šæ¯”ä¾‹': explained_variance_ratio,
          'ç´¯ç§¯æ–¹å·®è§£é‡Šæ¯”ä¾‹': cumulative_variance
      })
      
      st.dataframe(pca_summary.round(4), use_container_width=True)
      
      # ç¢çŸ³å›¾
      fig_scree = px.line(
          x=range(1, len(explained_variance_ratio) + 1),
          y=explained_variance_ratio,
          title="ç¢çŸ³å›¾",
          labels={'x': 'ä¸»æˆåˆ†', 'y': 'æ–¹å·®è§£é‡Šæ¯”ä¾‹'}
      )
      fig_scree.add_scatter(
          x=list(range(1, len(explained_variance_ratio) + 1)),
          y=explained_variance_ratio,
          mode='markers',
          marker=dict(size=8)
      )
      st.plotly_chart(fig_scree, use_container_width=True)
      
      # ä¸»æˆåˆ†è½½è·çŸ©é˜µ
      st.markdown("### ä¸»æˆåˆ†è½½è·çŸ©é˜µ")
      
      n_components_show = min(5, len(selected_vars))
      loadings = pd.DataFrame(
          pca.components_[:n_components_show].T,
          columns=[f'PC{i+1}' for i in range(n_components_show)],
          index=selected_vars
      )
      
      st.dataframe(loadings.round(4), use_container_width=True)
      
      # åŒæ ‡å›¾ï¼ˆå‰ä¸¤ä¸ªä¸»æˆåˆ†ï¼‰
      if len(pca_result) > 0:
          fig_biplot = px.scatter(
              x=pca_result[:, 0],
              y=pca_result[:, 1],
              title="PCAåŒæ ‡å›¾ (PC1 vs PC2)",
              labels={'x': f'PC1 ({explained_variance_ratio[0]:.1%})', 
                     'y': f'PC2 ({explained_variance_ratio[1]:.1%})'}
          )
          st.plotly_chart(fig_biplot, use_container_width=True)

def create_group_comparison_plot(data: pd.DataFrame, y_var: str, group_var: str, title: str):
  """åˆ›å»ºç»„é—´æ¯”è¾ƒå›¾"""
  fig = make_subplots(
      rows=1, cols=2,
      subplot_titles=["ç®±çº¿å›¾", "å°æç´å›¾"]
  )
  
  # ç®±çº¿å›¾
  for group in data[group_var].unique():
      if pd.notna(group):
          group_data = data[data[group_var] == group][y_var].dropna()
          fig.add_trace(
              go.Box(y=group_data, name=str(group), showlegend=False),
              row=1, col=1
          )
  
  # å°æç´å›¾
  for group in data[group_var].unique():
      if pd.notna(group):
          group_data = data[data[group_var] == group][y_var].dropna()
          fig.add_trace(
              go.Violin(y=group_data, name=str(group), showlegend=False),
              row=1, col=2
          )
  
  fig.update_layout(title_text=title, showlegend=False)
  fig.update_yaxes(title_text=y_var)
  
  return fig

def create_ttest_visualization(data: pd.Series, test_value: float, result: dict):
  """åˆ›å»ºtæ£€éªŒå¯è§†åŒ–"""
  fig = make_subplots(
      rows=1, cols=2,
      subplot_titles=["æ•°æ®åˆ†å¸ƒ", "tç»Ÿè®¡é‡åˆ†å¸ƒ"]
  )
  
  # æ•°æ®åˆ†å¸ƒç›´æ–¹å›¾
  fig.add_trace(
      go.Histogram(x=data.dropna(), name="æ•°æ®åˆ†å¸ƒ", showlegend=False),
      row=1, col=1
  )
  
  # æ·»åŠ å‡å€¼å’Œæ£€éªŒå€¼çº¿
  fig.add_vline(x=data.mean(), line_dash="dash", line_color="red", 
                annotation_text=f"æ ·æœ¬å‡å€¼: {data.mean():.2f}", row=1, col=1)
  fig.add_vline(x=test_value, line_dash="dash", line_color="blue",
                annotation_text=f"æ£€éªŒå€¼: {test_value:.2f}", row=1, col=1)
  
  # tåˆ†å¸ƒ
  from scipy.stats import t
  df = result['degrees_of_freedom']
  x_range = np.linspace(-4, 4, 1000)
  t_dist = t.pdf(x_range, df)
  
  fig.add_trace(
      go.Scatter(x=x_range, y=t_dist, name="tåˆ†å¸ƒ", showlegend=False),
      row=1, col=2
  )
  
  # æ·»åŠ tç»Ÿè®¡é‡çº¿
  fig.add_vline(x=result['statistic'], line_dash="dash", line_color="red",
                annotation_text=f"t = {result['statistic']:.3f}", row=1, col=2)
  
  fig.update_layout(title_text="å•æ ·æœ¬tæ£€éªŒå¯è§†åŒ–")
  
  return fig
